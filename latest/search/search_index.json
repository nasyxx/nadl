{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>nadl</code>","text":"<p>Nasy's JAX/FLAX deep learning toolkit.</p>"},{"location":"api/","title":"API","text":"<p>Python \u2661 Nasy.</p> <pre><code>|             *         *\n|                  .                .\n|           .                              \u767b\n|     *                      ,\n|                   .                      \u81f3\n|\n|                               *          \u6056\n|          |\\___/|\n|          )    -(             .           \u8056 \u00b7\n|         =\\ -   /=\n|           )===(       *\n|          /   - \\\n|          |-    |\n|         /   -   \\     0.|.0\n|  NASY___\\__( (__/_____(\\=/)__+1s____________\n|  ______|____) )______|______|______|______|_\n|  ___|______( (____|______|______|______|____\n|  ______|____\\_|______|______|______|______|_\n|  ___|______|______|______|______|______|____\n|  ______|______|______|______|______|______|_\n|  ___|______|______|______|______|______|____\n</code></pre> <p>author   : Nasy https://nasy.moe date     : Nov 29, 2023 email    : Nasy nasyxx+python@gmail.com filename : init.py project  : nadl license  : GPL-3.0+</p> <p>NADL</p>"},{"location":"api/#nadl.Keys","title":"<code>Keys</code>","text":"<p>             Bases: <code>NamedTuple</code></p> <p>JAX random key sequence.</p> Source code in <code>nadl/keys.py</code> <pre><code>class Keys(NamedTuple):\n  \"\"\"JAX random key sequence.\"\"\"\n\n  key: jax.Array\n  subkeys: deque[jax.Array]\n</code></pre>"},{"location":"api/#nadl.PG","title":"<code>PG</code>","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Progress.</p> Source code in <code>nadl/loops.py</code> <pre><code>class PG(NamedTuple):\n  \"\"\"Progress.\"\"\"\n\n  pg: Progress\n  console: Console\n  tasks: dict[str, TaskID]\n</code></pre>"},{"location":"api/#nadl.accuracy","title":"<code>accuracy(y_true, y_pred, normalize=True)</code>","text":"<p>Accuracy.</p> Source code in <code>nadl/metrics.py</code> <pre><code>@partial(jax.jit, static_argnames=(\"normalize\",))\ndef accuracy(y_true: jax.Array, y_pred: jax.Array, normalize: bool = True) -&gt; jax.Array:\n  \"\"\"Accuracy.\"\"\"\n  return jnp.mean(y_true == y_pred) if normalize else jnp.sum(y_true == y_pred)\n</code></pre>"},{"location":"api/#nadl.auc","title":"<code>auc(fpr, tpr)</code>","text":"<p>Compute Area Under the Curve (AUC) from the ROC curve.</p> Source code in <code>nadl/metrics.py</code> <pre><code>@jax.jit\ndef auc(fpr: jax.Array, tpr: jax.Array) -&gt; jax.Array:\n  \"\"\"Compute Area Under the Curve (AUC) from the ROC curve.\"\"\"\n  # Sort by false positive rates\n  sorted_indices = jnp.argsort(fpr)\n  fpr, tpr = fpr[sorted_indices], tpr[sorted_indices]\n\n  # Compute the area using the trapezoidal rule\n  return jax.scipy.integrate.trapezoid(tpr, fpr)\n</code></pre>"},{"location":"api/#nadl.average_precision_score","title":"<code>average_precision_score(y_true, y_score)</code>","text":"<p>Compute average precision from prediction scores.</p> Source code in <code>nadl/metrics.py</code> <pre><code>def average_precision_score(y_true: jax.Array, y_score: jax.Array) -&gt; jax.Array:\n  \"\"\"Compute average precision from prediction scores.\"\"\"\n  # Compute precision-recall curve\n  precision, recall, _ = precision_recall_curve(y_true, y_score)\n  return jax.scipy.integrate.trapezoid(precision, recall)\n</code></pre>"},{"location":"api/#nadl.classit","title":"<code>classit(x, method='sigmoid', keepdims=True)</code>","text":"<p>Classify the array.</p> Source code in <code>nadl/utils.py</code> <pre><code>def classit(\n  x: jax.Array,\n  method: Literal[None, \"sigmoid\", \"softmax\"] = \"sigmoid\",\n  keepdims: bool = True,\n) -&gt; jax.Array:\n  \"\"\"Classify the array.\"\"\"\n  match method:\n    case \"sigmoid\":\n      return jnp.where(jax.nn.sigmoid(x) &gt; 0.5, 1, 0)  # noqa: PLR2004\n    case \"softmax\":\n      x = jax.nn.softmax(x)\n      return jnp.argmax(x, axis=-1, keepdims=keepdims)\n    case None:\n      return x\n    case _:\n      raise ValueError(f\"Unknown method {method}\")\n</code></pre>"},{"location":"api/#nadl.confusion_matrix","title":"<code>confusion_matrix(y_true, y_pred, num_classes=2)</code>","text":"<p>Compute confusion matrix.</p> Source code in <code>nadl/metrics.py</code> <pre><code>@partial(jax.jit, static_argnames=(\"num_classes\",))\ndef confusion_matrix(\n  y_true: jax.Array, y_pred: jax.Array, num_classes: int = 2\n) -&gt; jax.Array:\n  \"\"\"Compute confusion matrix.\"\"\"\n  return (\n    jnp.zeros((num_classes, num_classes), dtype=jnp.int32).at[(y_true, y_pred)].add(1)\n  )\n</code></pre>"},{"location":"api/#nadl.dice_coef","title":"<code>dice_coef(y_true, y_pred, eps=1e-08)</code>","text":"<p>Compute dice coefficient.</p> Source code in <code>nadl/metrics.py</code> <pre><code>def dice_coef(y_true: jax.Array, y_pred: jax.Array, eps: float = 1e-8) -&gt; jax.Array:\n  \"\"\"Compute dice coefficient.\"\"\"\n  y_true = jnp.asarray(y_true)\n  y_pred = jnp.asarray(y_pred)\n\n  intersection = jnp.sum(y_true * y_pred)\n  union = jnp.sum(y_true) + jnp.sum(y_pred)\n\n  return (2.0 * intersection) / (union + eps)\n</code></pre>"},{"location":"api/#nadl.dice_loss","title":"<code>dice_loss(logits, labels, method='sigmoid')</code>","text":"<p>Dice loss.</p> Source code in <code>nadl/losses.py</code> <pre><code>def dice_loss(\n  logits: jax.Array,\n  labels: jax.Array,\n  method: Literal[None, \"sigmoid\", \"softmax\"] = \"sigmoid\",\n) -&gt; jax.Array:\n  \"\"\"Dice loss.\"\"\"\n  if labels.ndim == 1:\n    labels = labels[:, None]\n  if logits.ndim == 1:\n    logits = classit(logits[:, None], method=method)\n  return jax.vmap(dice_coef)(labels, logits)\n</code></pre>"},{"location":"api/#nadl.f1_score","title":"<code>f1_score(y_true, y_pred, num_classes=2, eps=1e-08)</code>","text":"<p>Compute the F1 score.</p> Source code in <code>nadl/metrics.py</code> <pre><code>@partial(jax.jit, static_argnames=(\"num_classes\", \"eps\"))\ndef f1_score(\n  y_true: jax.Array, y_pred: jax.Array, num_classes: int = 2, eps: float = 1e-8\n) -&gt; jax.Array:\n  \"\"\"Compute the F1 score.\"\"\"\n  _, _, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, num_classes, eps)\n  return f1_score\n</code></pre>"},{"location":"api/#nadl.from_int_or_key","title":"<code>from_int_or_key(key)</code>","text":"<p>Convert int or key to Keys.</p> Source code in <code>nadl/keys.py</code> <pre><code>def from_int_or_key(key: jax.Array | int) -&gt; Keys:\n  \"\"\"Convert int or key to Keys.\"\"\"\n  if isinstance(key, int):\n    return Keys(jax.random.key(key), deque())\n  return Keys(key, deque())\n</code></pre>"},{"location":"api/#nadl.from_state","title":"<code>from_state(key, subkeys)</code>","text":"<p>Convert state to Keys.</p> Source code in <code>nadl/keys.py</code> <pre><code>def from_state(key: jax.Array, subkeys: Sequence[jax.Array]) -&gt; Keys:\n  \"\"\"Convert state to Keys.\"\"\"\n  return Keys(key, deque(subkeys))\n</code></pre>"},{"location":"api/#nadl.identity_scaler","title":"<code>identity_scaler(arr, axis=0)</code>","text":"<p>Get identity scaler.</p> Source code in <code>nadl/preprocessing.py</code> <pre><code>def identity_scaler(arr: jax.Array, axis: int = 0) -&gt; SCALER:\n  \"\"\"Get identity scaler.\"\"\"\n  del arr, axis\n  def scaler(x: jax.Array) -&gt; jax.Array:\n    \"\"\"Scaler.\"\"\"\n    return x\n\n  return scaler\n</code></pre>"},{"location":"api/#nadl.init_progress","title":"<code>init_progress(pg, console, total=True, bar_width=20, extra_columns=(), show_progress=True, theme=None)</code>","text":"<p>Init progress bar.</p> Source code in <code>nadl/loops.py</code> <pre><code>def init_progress(\n  pg: Progress | None,\n  console: Console | None,\n  total: bool = True,\n  bar_width: int | None = 20,\n  extra_columns: tuple[ProgressColumn, ...] = (),\n  show_progress: bool = True,\n  theme: Theme | None = None,\n) -&gt; PG:\n  \"\"\"Init progress bar.\"\"\"\n  if console is None:\n    console = Console(theme=theme or DEF_LIGHT_THEME)\n  if pg is None:\n    pg = Progress(\n      TextColumn(\n        \"{task.description}\" + \" - {task.completed}/{task.total}\" if total else \"\"\n      ),\n      TimeRemainingColumn(),\n      TimeElapsedColumn(),\n      BarColumn(bar_width),\n      console=console,\n      disable=not show_progress,\n    )\n  pg.columns = pg.columns + extra_columns\n  return PG(pg, pg.console, {})\n</code></pre>"},{"location":"api/#nadl.iou","title":"<code>iou(y_true, y_pred, eps=1e-08)</code>","text":"<p>Compute intersection over union.</p> Source code in <code>nadl/metrics.py</code> <pre><code>def iou(y_true: jax.Array, y_pred: jax.Array, eps: float = 1e-8) -&gt; jax.Array:\n  \"\"\"Compute intersection over union.\"\"\"\n  y_true = jnp.asarray(y_true)\n  y_pred = jnp.asarray(y_pred)\n\n  intersection = jnp.sum(y_true * y_pred)\n  union = jnp.sum(y_true) + jnp.sum(y_pred) - intersection\n\n  return intersection / (union + eps)\n</code></pre>"},{"location":"api/#nadl.min_max_scaler","title":"<code>min_max_scaler(arr, axis=0)</code>","text":"<p>Get min max scaler.</p> Source code in <code>nadl/preprocessing.py</code> <pre><code>def min_max_scaler(arr: jax.Array, axis: int = 0) -&gt; SCALER:\n  \"\"\"Get min max scaler.\"\"\"\n  min_, max_ = arr.min(axis=axis, keepdims=True), arr.max(axis=axis, keepdims=True)\n\n  def scaler(x: jax.Array) -&gt; jax.Array:\n    \"\"\"Scaler.\"\"\"\n    return (x - min_) / (max_ - min_)\n\n  return scaler\n</code></pre>"},{"location":"api/#nadl.next_key","title":"<code>next_key(keys)</code>","text":"<p>Get next key.</p> Source code in <code>nadl/keys.py</code> <pre><code>def next_key(keys: Keys) -&gt; Keys:\n  \"\"\"Get next key.\"\"\"\n  if not keys.subkeys:\n    keys = reverse(keys, 1)\n  return from_state(keys.subkeys.popleft(), keys.subkeys)\n</code></pre>"},{"location":"api/#nadl.normalizer","title":"<code>normalizer(arr, axis=0, norm='l2')</code>","text":"<p>Get normalizer.</p> Source code in <code>nadl/preprocessing.py</code> <pre><code>def normalizer(\n  arr: jax.Array, axis: int = 0, norm: Literal[\"l1\", \"l2\", \"max\"] = \"l2\"\n) -&gt; SCALER:\n  \"\"\"Get normalizer.\"\"\"\n  match norm:\n    case \"l2\":\n      norm_value = jnp.sqrt(jnp.sum(jnp.square(arr), axis=axis, keepdims=True))\n    case \"l1\":\n      norm_value = jnp.sum(jnp.abs(arr), axis=axis, keepdims=True)\n    case \"max\":\n      norm_value = jnp.max(jnp.abs(arr), axis=axis, keepdims=True)\n    case _:\n      raise ValueError(\"norm should be 'l1', 'l2', or 'max'\")\n\n  def scaler(x: jax.Array) -&gt; jax.Array:\n    \"\"\"Scaler.\"\"\"\n    max_val = jnp.maximum(norm_value, jnp.finfo(x.dtype).tiny)  # Avoid division by zero\n    return x / max_val\n\n  return scaler\n</code></pre>"},{"location":"api/#nadl.precision_recall_curve","title":"<code>precision_recall_curve(y_true, y_score)</code>","text":"<p>Compute precision-recall pairs for different probability thresholds.</p> Source code in <code>nadl/metrics.py</code> <pre><code>def precision_recall_curve(\n  y_true: jax.Array, y_score: jax.Array\n) -&gt; tuple[jax.Array, jax.Array, jax.Array]:\n  \"\"\"Compute precision-recall pairs for different probability thresholds.\"\"\"\n  y_true = jnp.asarray(y_true)\n  y_score = jnp.asarray(y_score)\n\n  descending_order = jnp.argsort(y_score)[::-1]\n  y_score = y_score[descending_order]\n  y_true = y_true[descending_order]\n\n  # Precision and recall\n  distinct_value_indices = jnp.argwhere(jnp.diff(y_score))\n  threshold_idxs = jnp.r_[distinct_value_indices, y_true.size - 1]\n\n  tps = jnp.cumsum(y_true)[threshold_idxs]\n  fps = 1 + threshold_idxs - tps\n\n  precision = tps / (tps + fps)\n  recall = tps / jnp.sum(y_true)\n\n  thresholds = jnp.r_[jnp.inf, y_score[threshold_idxs]]\n\n  precision = jnp.r_[1, precision]\n  recall = jnp.r_[0, recall]\n\n  return precision, recall, thresholds\n</code></pre>"},{"location":"api/#nadl.precision_recall_fscore_support","title":"<code>precision_recall_fscore_support(y_true, y_pred, num_classes=2, eps=1e-08)</code>","text":"<p>Compute precision, recall, F-score and support for each class.</p> Source code in <code>nadl/metrics.py</code> <pre><code>@partial(jax.jit, static_argnames=(\"num_classes\", \"eps\"))\ndef precision_recall_fscore_support(\n  y_true: jax.Array, y_pred: jax.Array, num_classes: int = 2, eps: float = 1e-8\n) -&gt; tuple[jax.Array, jax.Array, jax.Array, jax.Array]:\n  \"\"\"Compute precision, recall, F-score and support for each class.\"\"\"\n  # Create a confusion matrix\n  conf_matrix = confusion_matrix(y_true, y_pred, num_classes)\n\n  # Compute precision, recall for each class\n  true_positives = jnp.diag(conf_matrix)\n  predicted_positives = jnp.sum(conf_matrix, axis=0)\n  actual_positives = jnp.sum(conf_matrix, axis=1)\n\n  precision = true_positives / (predicted_positives + eps)\n  recall = true_positives / (actual_positives + eps)\n\n  # Compute F1 score\n  f1_score = 2 * (precision * recall) / (precision + recall + eps)\n\n  # Compute support for each class\n  support = actual_positives\n\n  return precision, recall, f1_score, support\n</code></pre>"},{"location":"api/#nadl.precision_score","title":"<code>precision_score(y_true, y_pred, num_classes=2, eps=1e-08)</code>","text":"<p>Compute the precision.</p> Source code in <code>nadl/metrics.py</code> <pre><code>@partial(jax.jit, static_argnames=(\"num_classes\", \"eps\"))\ndef precision_score(\n  y_true: jax.Array, y_pred: jax.Array, num_classes: int = 2, eps: float = 1e-8\n) -&gt; jax.Array:\n  \"\"\"Compute the precision.\"\"\"\n  precision, _, _, _ = precision_recall_fscore_support(y_true, y_pred, num_classes, eps)\n  return precision\n</code></pre>"},{"location":"api/#nadl.recall_scroe","title":"<code>recall_scroe(y_true, y_pred, num_classes=2, eps=1e-08)</code>","text":"<p>Compute the recall.</p> Source code in <code>nadl/metrics.py</code> <pre><code>@partial(jax.jit, static_argnames=(\"num_classes\", \"eps\"))\ndef recall_scroe(\n  y_true: jax.Array, y_pred: jax.Array, num_classes: int = 2, eps: float = 1e-8\n) -&gt; jax.Array:\n  \"\"\"Compute the recall.\"\"\"\n  _, recall, _, _ = precision_recall_fscore_support(y_true, y_pred, num_classes, eps)\n  return recall\n</code></pre>"},{"location":"api/#nadl.reverse","title":"<code>reverse(keys, num)</code>","text":"<p>Reverse the keys.</p> Source code in <code>nadl/keys.py</code> <pre><code>def reverse(keys: Keys, num: int) -&gt; Keys:\n  \"\"\"Reverse the keys.\"\"\"\n  key, subkeys = keys\n  while (num := num - 1) &gt;= 0:\n    if subkeys:\n      subkeys.append(jax.random.fold_in(subkeys[-1], 0))\n    else:\n      subkeys.append(jax.random.fold_in(key, 0))\n  return keys._replace(subkeys=subkeys)\n</code></pre>"},{"location":"api/#nadl.rle","title":"<code>rle(x, shift=1)</code>","text":"<p>Run length encoding.</p> Source code in <code>nadl/utils.py</code> <pre><code>def rle(x: jax.Array, shift: int = 1) -&gt; str:\n  \"\"\"Run length encoding.\"\"\"\n  return \" \".join(map(str, rle_array(x, shift)))\n</code></pre>"},{"location":"api/#nadl.rle_array","title":"<code>rle_array(x, shift=1)</code>","text":"<p>Run length encoding array.</p> Source code in <code>nadl/utils.py</code> <pre><code>def rle_array(x: jax.Array, shift: int = 1) -&gt; jax.Array:\n  \"\"\"Run length encoding array.\"\"\"\n  x = x.flatten()\n  x = jnp.pad(x, (1, 1), mode=\"constant\")\n  x = jnp.argwhere(x[1:] != x[:-1]).flatten() + shift\n  return x.at[1::2].add(-x[::2])\n</code></pre>"},{"location":"api/#nadl.roc_auc_score","title":"<code>roc_auc_score(y_true, y_score)</code>","text":"<p>Compute Area Under the ROC of AUC from prediction scores.</p> Source code in <code>nadl/metrics.py</code> <pre><code>def roc_auc_score(y_true: jax.Array, y_score: jax.Array) -&gt; jax.Array:\n  \"\"\"Compute Area Under the ROC of AUC from prediction scores.\"\"\"\n  # Compute ROC curve\n  fpr, tpr, _ = roc_curve(y_true, y_score)\n  return auc(fpr, tpr)\n</code></pre>"},{"location":"api/#nadl.roc_curve","title":"<code>roc_curve(y_true, y_score)</code>","text":"<p>Compute Receiver operating characteristic (ROC).  Cannot be jitted.</p> Source code in <code>nadl/metrics.py</code> <pre><code>def roc_curve(\n  y_true: jax.Array, y_score: jax.Array\n) -&gt; tuple[jax.Array, jax.Array, jax.Array]:\n  \"\"\"Compute Receiver operating characteristic (ROC).  Cannot be jitted.\"\"\"\n  y_true = jnp.asarray(y_true)\n  y_score = jnp.asarray(y_score)\n\n  descending_order = jnp.argsort(y_score)[::-1]\n  y_score = y_score[descending_order]\n  y_true = y_true[descending_order]\n\n  # TPR and FPR\n  distinct_value_indices = jnp.argwhere(jnp.diff(y_score))\n  threshold_idxs = jnp.r_[distinct_value_indices, y_true.size - 1]\n\n  tps = jnp.cumsum(y_true)[threshold_idxs]\n  fps = 1 + threshold_idxs - tps\n\n  tpr = tps / jnp.sum(y_true)\n  fpr = fps / jnp.sum(1 - y_true)\n\n  thresholds = jnp.r_[jnp.inf, y_score[threshold_idxs]]\n\n  tpr = jnp.r_[0, tpr]\n  fpr = jnp.r_[0, fpr]\n\n  return fpr, tpr, thresholds\n</code></pre>"},{"location":"api/#nadl.select_scaler","title":"<code>select_scaler(method='minmax', axis=0)</code>","text":"<p>Get scaler function.</p> Source code in <code>nadl/preprocessing.py</code> <pre><code>def select_scaler(\n  method: Literal[\"id\", \"minmax\", \"std\", \"l2_norm\", \"l1_norm\", \"max_norm\"] = \"minmax\",\n  axis: int = 0,\n) -&gt; Callable[[jax.Array], SCALER]:\n  \"\"\"Get scaler function.\"\"\"\n  match method:\n    case \"id\":\n      return partial(identity_scaler, axis=axis)\n    case \"minmax\":\n      return partial(min_max_scaler, axis=axis)\n    case \"std\":\n      return partial(standard_scaler, axis=axis)\n    case \"l2_norm\":\n      return partial(normalizer, norm=\"l2\", axis=axis)\n    case \"l1_norm\":\n      return partial(normalizer, norm=\"l1\", axis=axis)\n    case \"max_norm\":\n      return partial(normalizer, norm=\"max\", axis=axis)\n    case _:\n      raise ValueError(f\"Unknown scaler method {method}\")\n</code></pre>"},{"location":"api/#nadl.sigmoid_focal_loss","title":"<code>sigmoid_focal_loss(logits, labels, alpha=0.25, gamma=2.0)</code>","text":"<p>Focal loss.</p> Source code in <code>nadl/losses.py</code> <pre><code>def sigmoid_focal_loss(\n  logits: jax.Array, labels: jax.Array, alpha: float = 0.25, gamma: float = 2.0\n) -&gt; jax.Array:\n  \"\"\"Focal loss.\"\"\"\n  p = sigmoid(logits)\n  ce_loss = sigmoid_binary_cross_entropy(logits, labels)\n  p_t = p * labels + (1 - p) * (1 - labels)\n  loss = ce_loss * ((1 - p_t) ** gamma)\n\n  alpha_t = labels * alpha + (1 - labels) * (1 - alpha)\n  return alpha_t * loss\n</code></pre>"},{"location":"api/#nadl.softmax_focal_loss","title":"<code>softmax_focal_loss(logits, labels, alpha=0.25, gamma=2.0)</code>","text":"<p>Focal loss.</p> Source code in <code>nadl/losses.py</code> <pre><code>def softmax_focal_loss(\n  logits: jax.Array, labels: jax.Array, alpha: float = 0.25, gamma: float = 2.0\n) -&gt; jax.Array:\n  \"\"\"Focal loss.\"\"\"\n  focus = jnp.power(-jax.nn.softmax(logits, axis=-1) + 1.0, gamma)\n  loss = -labels * alpha * focus * jax.nn.log_softmax(logits, axis=-1)\n  return jnp.sum(loss, axis=-1)\n</code></pre>"},{"location":"api/#nadl.standard_scaler","title":"<code>standard_scaler(arr, axis=0)</code>","text":"<p>Get standard scaler.</p> Source code in <code>nadl/preprocessing.py</code> <pre><code>def standard_scaler(arr: jax.Array, axis: int = 0) -&gt; SCALER:\n  \"\"\"Get standard scaler.\"\"\"\n  mean, std = arr.mean(axis=axis, keepdims=True), arr.std(axis=axis, keepdims=True)\n\n  def scaler(x: jax.Array) -&gt; jax.Array:\n    \"\"\"Scaler.\"\"\"\n    return (x - mean) / std\n\n  return scaler\n</code></pre>"},{"location":"api/#nadl.support","title":"<code>support(y_true, y_pred, num_classes=2, eps=1e-08)</code>","text":"<p>Compute the support.</p> Source code in <code>nadl/metrics.py</code> <pre><code>@partial(jax.jit, static_argnames=(\"num_classes\", \"eps\"))\ndef support(\n  y_true: jax.Array, y_pred: jax.Array, num_classes: int = 2, eps: float = 1e-8\n) -&gt; jax.Array:\n  \"\"\"Compute the support.\"\"\"\n  _, _, _, support = precision_recall_fscore_support(y_true, y_pred, num_classes, eps)\n  return support\n</code></pre>"},{"location":"api/#nadl.take","title":"<code>take(keys, num)</code>","text":"<p>Take num keys.</p> Source code in <code>nadl/keys.py</code> <pre><code>def take(keys: Keys, num: int) -&gt; tuple[Keys, ...]:\n  \"\"\"Take num keys.\"\"\"\n  keys = reverse(keys, max(num - len(keys.subkeys), 0))\n  return tuple(map(lambda _: next_key(keys), range(num)))\n</code></pre>"}]}